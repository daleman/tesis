\section{Conclusiones y trabajo futuro}
En el presente trabajo multidisciplinario desarrollamos una métrica de la contrastividad de uso de una palabra en distintas regiones. Para probar esta métrica recolectamos un conjunto de datos de textos de la Argentina a través de la API de Twitter.

La métrica que creamos usa la entropía para medir la variación de la cantidad de ocurrencias y de la cantidad de usuarios que la utilizaron en las diferentes provincias del país. Se seleccionaron las 5000 palabras con mayor valor de contrastividad para realizar una validación lingüística por parte de la Academia Argentina de Letras. La validación arrojó un resultado con alrededor de 300 palabras dignas de estudio de esas 5000 palabras, es decir, 1 palabra cada 17. 
A pesar de que no existen otros proyectos que provean un término de comparación para evaluar el grado de éxito implicado en esta relación, no caben dudas de que, al menos en la detección de coloquialismos locales actualmente en uso, la herramienta plantea un verdadero punto de inflexión para la lexicografía contrastiva.
Varias de las palabras detectadas a partir de la métrica desarrollada serán agregadas al Diccionario del Habla de los Argentinos.

En cuanto a la validación estadística, dejamos como trabajo futuro el cálculo de un análisis estadístico aplicable a nuestra métrica, ya que está por fuera del alcance de esta tesis. Sin embargo, en base al análisis hecho a través del test t de Welch también tenemos indicios de las virtudes de la métrica desarrollada. 

En este trabajo se analizan las regiones formadas con una provincia como unidad regional, pero esta se puede cambiar para replicar el análisis con distinta granularidad. De esta manera se podrían ver las palabras contrastivas en los distintos países hispanoparlantes y comparar las variaciones entre regiones más grandes o bien, replicar el trabajo en el interior de una sola provincia o ciudad.

Uno de los desafíos que dispara este trabajo es el de poder identificar regiones/clusters con usos dialectales diferentes. A su vez, permitiría validar la vigencia de las regiones propuestas por Vidal de Battini en 1964 \cite{vidal1964espanol}.

También, el proceso de normalización se podría mejorar para tener una mayor precisión en las palabras utilizadas. A partir de una mejor normalización y de la lematización con información metalingüística del corpus, podríamos trascender el ámbito de léxico para estudiar los fenómenos sintácticos del español, como su variación en distintas regiones. Continuando con la línea de investigación se podría analizar la contrastividad léxica comparando la distribución de n-gramas. Por otro lado, sería útil agregar un sistema de reconocimiento de nombres de entidades para destacar ciertos nombres propios, de manera tal que el listado de palabras tenga más alertas sobre términos sin interés lingüístico.

Es importante señalar las ventajas de \textit{Twitter} ya que nos permitió recolectar un volumen grande de datos de texto, escritos por distintas personas con información de su localización. En cuanto a las desventajas de esta plataforma podemos destacar los errores ortográficos de los textos, la modificación intencionada de las palabras para generar énfasis o con motivo de una escritura más rápida. Todo esto conlleva a un aumento de la dificultad para normalizar el texto. Creemos, a pesar de todo esto, que el volumen de datos prevalece a la hora de decidir una plataforma para recolectarlos.

% En cuanto a las desventajas de esta plataforma podemos destacar los errores ortográficos de los textos. Sin embargo, la modificación intencionada de las palabras con fines expresivos o debido a que, además de la limitación de espacio, el usuario tiende a practicar una escritura más rápida. Con todo, es indudable que esto conlleva a un aumento de la dificultad para normalizar el texto. Creemos, a pesar de todo esto, que el volumen de datos prevalece a la hora de decidir una plataforma para recolectarlos.
